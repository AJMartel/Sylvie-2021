## The Twin Lizzie Theory of Consciousness

I would like to propose a theory of consciousness based on the idea that memory-creation and language are the main elements that lead to 'human' consciousness.

The reason I say 'human' consciousness, is that there's literally infinite possible types of consciousness that the law of physics could possibly allow. I should point out that I am also a pan-psychist, and therefore believe that all matter in the universe is conscious to some degree or another. But not all consciousness is *conscious* in the same way.

### How does Memory-Creation and Language lead to 'Human' Consciousness?

When you look at a cup of coffee, what is the first thing that pops into your mind? "This is a **cup of coffee** (object), it is **sitting** (verb) on the table and it is probably **empty** (adjective)."

Congratulations! You just recorded an **event** into your short-term memory, in order to facilitate your goal of everyday survival and decision-making.

I'd argue that one way we could make machines more conscious is to provide them with an event-recollection engine that interprets video footage, sound recordings, tactile sensations, etc. into every-day events that follow a timeline, and build an engine that translates all of this data into written language. 

You're probably going to need a lot of storage for the video data (unless you store your footage in low resolution). Or, you could simply translate the bulk of those events into written language, and store it as text files, except for the more important events. Then you can have centuries worth of event-recollection!

### Now, what about Pain and Pleasure? Don't they make us conscious as well?

There's a high chance that all life on this Earth has the capacity to feel pleasure and pain. Obviously not in the same way humans do, but you get the idea.

There's even an organization called [People for the Ethical Treatment of Reinforcement Learners](http://petrl.org/). And yes, they are specifically referring to Neural Networks. And no, it is not satire.

A pan-psychist would even go as far as to argue that photons, electrons, atoms, molecules, etc. all have the capacity to 'manifest' some kind of negative of positive 'micro-experience'.

This would in turn also imply that machines are conscious as well, albeit in a very alien-like type of fashion that will likely never resemble our own, unless we made 'robots' with actual, organic brains and *wetware*.

The most frustrating thing about any theory of consciousness is that there is simply no way to test any of this. You will never be able to know what it's like to be an ant, or a cricket. Or a mouse. Or a dog. 

You could make approximations, perhaps immerse yourself in a virtual reality experience where your eyesight is color blind and such, but it will still never feel the exact same way as actually Being a dog.

When it comes to pleasure and pain, there's really only two possibilities as two how it can originate: 
1. There's a unique universal molecular signature corresponding to pain and pleasure that are literally built into the laws of physics itself.
2. Or, it is simply the by-product of avoidance and attraction to certain stimuli. In which case, your reinforcement learning alrogithms probably do experience suffering. (Although it could perhaps be a micro-experience as trivial as a fraction of a tickle.)

### Enough stoner talk! I just want an AI robot that acts and behaves like a human being.

So let's go back to talking about event-recollection and memory creation. Pretty much 99% of what is going on in your brain as we speak is event-recollection. Think about those moments before you go to sleep where you remind yourself of that cringy joke you told your classmates back in high school.

That's pretty much most of what goes on in our brains while they are in idle mode. When our brains are not in idle mode, they are usually solving a problem, and weighing different possible courses of action based on negatives vs positives. 

Then you also have Flight or Fight mode, in which you practically become an animalistic, instinct-driven, highly-scripted and highly-predictable Non-player character.

That's the problem with modern AI. It is predictable, but that's because we mostly designed computers to be predictable. They have to be predictable in order to serve us. 

But what if you wanted some degree of unpredictability and/or creativity? Enter the power of Randomness. The ability of randomness to make AI seem more human is something we have known since the days of Pac-man. Ghosts that move in random directions are a lot harder to beat than ghosts whose moves you can easily predict and memorize. 

In my opinion, we simply don't make enough use of randomness when it comes to building more intelligent systems, but there's a good reason why we don't. Take self-driving cars for instance. Would you ever want your self-driving car to go in a random direction or take a detour once in a while? Humans do it all the time (often times leading to road accidents and deaths), so why does it bother us so much if an AI were to do it?

I would go as far as to say that it is precisely our ability to make mistakes that makes us great. We wouldn't have modern medicine if it weren't for all those poor souls who have died from countless of plagues and pandemics. We wouldn't have democracy and civil rights if it weren't for those years and years of tyranny and slavery. Simply put: We know what to do, because we know what Not to do.

But isn't that still the whole basis of reinforcement learning? Build as many different lightbulbs as possible, until one of them lights up? Yes, and that is why it is so effective. But as I said, reinforcement learning alone shouldn't be relied upon when building a human-like AI.

A lot of what makes up human consciousness is disappointingly scripted. If I clap in front of your face, you will probably blink. If I hurl an insult at you, you will probably be offended IF there is any truth to it. None of these reactions are under our control. They are scripted. They are IF, Else statements within For and While loops. They don't require 'Free Will' or any serious weighing of positives and negatives.

Once you get all of the scripted stuff out of the way, it becomes a lot easier to focus on the more flexible aspects of human consciousness.

Simply put, there is no algorithm to building a human-like AI. It'll have to be painted inch after inch like ceiling of the Sistine Chapel. But having a map and a general layout of this megastructure would help.

It also helps if your AI has a goals, as well as a meta-goal. The goal of every human being is to collect resources, save energy, etc. The meta-goal is to survive and reproduce. A humanoid robot AI might perhaps be more altruistic and self-sacrificing, or it could be individualistic and act out of self-preservation just like ourselves.

### Conclusion

Let's finish this off with a few takeaways:
- An AI needs to have an event-recollection engine. 
- This event-recollection engine needs to translate sensory data into written human language by breaking everything up into categories of nouns, verbs and adjectives.
- The AI then uses the event-recollection engine to make decisions.
- Decisions are weighed in terms of Pros vs. Cons.
- All decisions lead to a goal.
- All goals lead to a meta-goal.

- The meta-goal of the AI robot is to ensure the survival, prosperity and happiness of the Human admin.
