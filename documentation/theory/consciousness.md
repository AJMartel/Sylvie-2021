## The Twin Lizzie Theory of Consciousness

I would like to propose a theory of consciousness based on the idea that memory-creation and language are the main elements that could lead to 'human' consciousness.

The reason I say 'human' consciousness, is that the laws of physics should in theory allow for infinite variations or modes of *being*.

Consciousness could even be quantifiable on a spectrum, with one end of the spectrum representing 'complex' consciousness like humans and
chimpanzees, and the other end representing 'simple' life forms like ants, bees, microbes and plants.

I should point out that I am also a pan-psychist. If all the hydrogen and carbon molecules in our bodies are indistinguishable from that of a rock sitting at the bottom of the ocean, or a nearby gas giant in outer space, who is to say that the rock isn't *alive*? If all that's going on in our brains are just chemical reactions following the basic laws of physics, who is to say that Jupiter isn't alive and conscious? 

### How does Memory-Creation and Language lead to 'Human' Consciousness?

Language could be thought of as a tool that we use in order to [transfer our own reality onto the minds of others](https://en.wikipedia.org/wiki/Language_and_thought), but it also seems to be an ingredient that makes up actual *thought*.

Why does talking about a problem help us think more logically? Why does writing things down on paper have the same effect on memory and learning?

Are Language and Thought just one and the same? What came first, [the chicken or the egg?](https://www.youtube.com/watch?v=_UqxSq19_Aw)

One thing we do know is that Language seems to give us the infrastructure to work with Logic and Concepts, just as Math gives us the infrastructure to work with numbers. Language is Command. Language is Statement. Language is Code.

### Language as an Encoder of reality

When you look at a cup of coffee, what is the first thing that pops into your mind? "This is a **cup of coffee** (object), it is **sitting** (verb) on the table and it is probably **empty** (adjective). Is it a threat to my survival? No. Is it food? Yes. Is it alive? No."

Congratulations! You just recorded an **event** into your short-term memory, in order to facilitate your goal of everyday survival and decision-making.

One way we could make machines more conscious is to provide them with an event-recollection engine that translates video footage, sound recordings, tactile sensations, etc. into every-day events that follow a timeline.

So rather than having a directory full of raw video footage, sound recordings, touch sensor data logs, etc. you would simply have written transcripts of events that took place on a certain day, at a certain time.

### A Basic Example of our 'Reality Encoder'

08/07/2020, 11:00am: *New context/location: Bedroom 2, at house Number X, at address X*<br/>
08/07/2020, 11:58am: A cat has entered current location.<br/>
08/07/2020, 11:59am: A cat has licked its paw.<br/>
08/07/2020, 12:05pm: Admin has entered current location.<br/>
08/07/2020, 12:05pm: Admin sat down by the desk.<br/>
08/07/2020, 12:30pm: Admin stood up and made a cup of coffee.<br/>
08/07/2020, 12:45pm: A cat scratched the carpet.<br/>
08/07/2020, 1:00pm: *New context/location: Bedroom 1, at house Number X, at address X*<br/>
08/07/2020, 1:20pm: Admin has left the current location.<br/>

As is the case with our own minds, the AI has to be able to decide what kind of information is to be recorded, and what kind of information
has to be filtered out, in order to avoid an information-overload. Usually our minds only remember interesting events, like a sudden
change in our environments.

Obviously, the more processing power your AI has, the more data it'll be able to process and record about the environment. A simple AI might remember that A Cat entered its current location and licked its paw, but it probably won't be concerned with whether it licked its Left paw, or its Right paw. (Unless you specifically instruct the AI to look out for these details for whatever reason.)   

You're probably going to need a lot of storage for the video data (unless you store your footage in low resolution). Or, you could simply translate the bulk of those events into written language, and store it as text files, except for the more important events where photographic memory is vital. Then you can have centuries worth of event-recollection!

### Decoding written Language back into Reality?

As a bonus, your AI will also even be able to decode every event it has recorded back into video and sound using deep learning.

We already have deep learning algorithms that can turn words and sentences into photograps e.g. "A golden retriever is playing frisbee in the backyard."

Keep in mind, though, that once you decode an already encoded version of an event, a lot of the original detail will be lost.

But that is exactly what happens when we remember an event, and then try to describe the event to somebody else: The other person will
never be able to know *what exactly it was like to be there and witness it*, but they will still have a *vague picture* of the event in their heads. But in most cases, that is all that is required for successful communication!

### Now, what about Pain and Pleasure? Don't they make us conscious as well?

There's a high chance that all life on this Earth has the capacity to feel pleasure and pain. Obviously not in the same way humans do, but you get the idea.

There's even an organization called [People for the Ethical Treatment of Reinforcement Learners](http://petrl.org/). And yes, they are specifically referring to Neural Networks. And no, it is not satire.

A pan-psychist would even go as far as to argue that photons, electrons, atoms, molecules, etc. all have the capacity to 'manifest' some kind of negative of positive 'micro-experience'.

This would in turn also imply that machines are conscious as well, albeit in a very alien-like type of fashion that will likely never resemble our own, unless we made 'robots' with actual, organic brains and *wetware*.

The most frustrating thing about any theory of consciousness is that there is simply no way to test any of this. You will never be able to know what it's like to be an ant, or a cricket. Or a mouse. Or a dog. 

You could make approximations, perhaps immerse yourself in a virtual reality experience where your eyesight is color blind and such, but it will still never feel the exact same way as actually Being a dog.

When it comes to pleasure and pain, there's really only two possibilities as two how it can originate: 
1. There's a unique universal molecular signature corresponding to pain and pleasure that are literally built into the laws of physics itself.
2. Or, it is simply the by-product of avoidance and attraction to certain stimuli. In which case, your reinforcement learning alrogithms probably do experience suffering. (Although it could perhaps be a micro-experience as trivial as a fraction of a tickle.)

### But we just want an AI robot that acts and behaves like a human being.

So let's go back to talking about event-recollection and memory creation. Pretty much 99% of what is going on in your brain as we speak is event-recollection. Think about those moments before you go to sleep where you remind yourself of that cringy joke you told your classmates back in high school.

That's pretty much most of what goes on in our brains while they are in idle mode. When our brains are not in idle mode, they are usually solving a problem, and weighing different possible courses of action based on negatives vs positives. 

Then you also have Flight or Fight mode, in which you practically become an animalistic, instinct-driven, highly-scripted and highly-predictable Non-player character.

That's the problem with modern AI. It is predictable, but that's because we mostly designed computers to be predictable. They have to be predictable in order to serve us. 

But what if you wanted some degree of unpredictability and/or creativity? Enter the power of Randomness. The ability of randomness to make AI seem more human is something we have known since the days of Pac-man. Ghosts that move in random directions are a lot harder to beat than ghosts whose moves you can easily predict and memorize. 

In my opinion, we simply don't make enough use of randomness when it comes to building more intelligent systems, but there's a good reason why we don't. Take self-driving cars for instance. Would you ever want your self-driving car to go in a random direction or take a detour once in a while? Humans do it all the time (often times leading to road accidents and deaths), so why does it bother us so much if an AI were to do it?

I would go as far as to say that it is precisely our ability to make mistakes that makes us great. We wouldn't have modern medicine if it weren't for all those poor souls who have died from countless of plagues and pandemics. We wouldn't have democracy and civil rights if it weren't for those years and years of tyranny and slavery. Simply put: We know what to do, because we know what Not to do.

### Isn't this just stating the obvious?

But isn't that still the whole basis of reinforcement learning? Build as many different lightbulbs as possible, until one of them lights up? Yes, and that is why it is so effective. But as I said, reinforcement learning alone shouldn't be relied upon when building a human-like AI.

A lot of what makes up human consciousness is disappointingly scripted. If I clap in front of your face, you will probably blink. If I hurl an insult at you, you will probably be offended IF there is any truth to it. None of these reactions are under our control. They are scripted. They are IF, Else statements within For and While loops. They don't require 'Free Will' or any serious weighing of positives and negatives.

Once you get all of the scripted stuff out of the way, it becomes a lot easier to focus on the more flexible aspects of human consciousness.

Simply put, there is no magic recipe to building a human-like AI. It'll have to be painted inch after inch like ceiling of the Sistine Chapel. But having a map and a general layout of this megastructure would help.

It also helps if your AI has a goal, as well as a meta-goal. The goal of every human being is to collect resources, save energy, etc. The meta-goal is to survive and reproduce. A humanoid robot AI might perhaps be more altruistic and self-sacrificing, or it could be individualistic and act out of self-preservation just like ourselves.

### Most of what goes on inside of our minds is analog noise

That's right. Most of what goes on in our minds is just analog noise. And you have to remember that the human mind doesn't always act 
in its own best interests. It only acts upon what it believes will increase your chances of surviving and reproducing in the natural environment.

But modern life isn't a natural environment, and a lot of the behaviors that used to benefit us in ancient times are now starting
to work against our own best interests. The human brain is the worst computer you could possibly emulate.

Once you filter out the noise, it becomes a lot easier to just isolate the elements of human consciousness that are any good, and then simply get rid of the rest. 

Unless you want your robot to have dreams. But do we ever really enjoy listening to people talk about what they dreamed last night?

### Which Sci-fi movie do you think gets Aritificial Intelligence right?

In my opinion, the movie [Arrival](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01631/full). And it's actually about Aliens, not AI.

### Conclusion

Let's finish this off with a few takeaways:
- An AI needs to have an event-recollection engine. 
- This event-recollection engine needs to translate sensory data into written human language by breaking everything up into categories of nouns, verbs and adjectives.
- The AI then uses the event-recollection engine to make decisions.
- Decisions are weighed in terms of Pros vs. Cons.
- All decisions lead to a goal.
- All goals lead to a meta-goal.

- The meta-goal of the AI robot is to ensure the survival, prosperity and happiness of the Human admin.
